
# 联邦学习项目代码工作原理

## 1. 系统架构概述

该联邦学习项目实现了一个非交互式联邦学习系统，主要由以下核心组件构成：

1. **主程序入口**：`main.py`和`quick_start.py`
2. **数据处理模块**：负责数据集加载和非IID数据分发
3. **模型定义**：针对不同数据集的神经网络模型
4. **联邦学习核心**：实现客户端训练和服务器聚合
5. **实验记录**：训练结果保存和管理
6. **可视化服务**：`web_visualizer.py`提供Web界面展示结果

整个系统模拟了真实环境中的联邦学习过程，但在单机上执行，通过软件模拟多个客户端的行为。

## 2. 工作流程详解

### 2.1 系统初始化阶段

1. **配置加载**：从`federated_learning.json`或`federated_learning_quick.json`读取配置参数
2. **数据集准备**：加载指定数据集(MNIST/Fashion-MNIST/CIFAR-10)
3. **数据分发**：根据非IID设置将数据分配给模拟的各个客户端
4. **模型初始化**：根据数据集类型初始化适合的神经网络模型

代码示例（配置加载）：
```python
# 加载配置文件
with open('federated_learning.json', 'r') as f:
    config = json.load(f)

# 提取关键参数
dataset = config['dataset']
n_clients = config['n_clients']
batch_size = config['batch_size']
rounds = config['rounds']
```

### 2.2 联邦学习流程

系统实现了标准的FedAvg算法，工作流程如下：

1. **服务器初始化全局模型**
2. **通信轮次循环**：
   - 服务器选择一部分客户端参与当前轮次（基于participation_rate）
   - 选中的客户端接收最新全局模型
   - 各客户端使用本地数据进行模型训练（多个本地迭代epoch）
   - 客户端将更新后的模型参数发送给服务器
   - 服务器进行加权平均聚合，更新全局模型
   - 服务器评估当前全局模型性能
3. **结果记录**：定期记录训练和测试的精度与损失

核心代码流程（简化）：
```python
# 初始化全局模型
global_model = init_model(dataset)

for round in range(rounds):
    # 选择参与客户端
    selected_clients = select_clients(n_clients, participation_rate)
    
    client_updates = []
    client_samples = []
    
    # 客户端本地训练
    for client_id in selected_clients:
        # 获取客户端本地数据
        local_data = client_data[client_id]
        
        # 复制全局模型到客户端
        local_model = copy.deepcopy(global_model)
        
        # 客户端本地训练
        local_model = train_local_model(local_model, local_data, lr, epochs)
        
        # 收集客户端更新和样本数量（用于加权平均）
        client_updates.append(local_model.state_dict())
        client_samples.append(len(local_data))
    
    # 服务器聚合更新
    global_model = federated_avg(global_model, client_updates, client_samples)
    
    # 评估全局模型
    test_accuracy, test_loss = evaluate_model(global_model, test_data)
    
    # 记录结果
    log_results(round, test_accuracy, test_loss)
```

### 2.3 非IID数据分布实现

系统支持非独立同分布(non-IID)数据，通过以下机制实现：

1. **类别限制**：通过`classes_per_client`参数控制每个客户端拥有的类别数
2. **数据平衡度**：通过`balancedness`参数控制数据分布的均衡程度

实现代码（简化）：
```python
def distribute_data_to_clients(dataset, n_clients, classes_per_client, balancedness):
    # 按类别分组数据
    data_by_class = group_data_by_class(dataset)
    
    # 为每个客户端分配类别
    client_classes = assign_classes_to_clients(n_clients, classes_per_client)
    
    # 为每个客户端分配数据
    client_data = {}
    for client_id in range(n_clients):
        # 获取该客户端的类别
        classes = client_classes[client_id]
        
        # 从这些类别中采样数据（考虑balancedness参数）
        client_data[client_id] = sample_data_for_client(
            data_by_class, classes, balancedness
        )
    
    return client_data
```

### 2.4 模型评估与记录

系统定期评估全局模型性能并记录结果：

1. **精度和损失计算**：在测试集和训练集上评估模型
2. **结果存储**：以`.npz`格式保存在`results/`目录下
3. **结果内容**：包含准确率、损失、通信轮次、超参数等信息

```python
def evaluate_and_log(model, test_loader, train_loader, round, results):
    # 计算测试集性能
    test_accuracy, test_loss = evaluate(model, test_loader)
    
    # 计算训练集性能
    train_accuracy, train_loss = evaluate(model, train_loader)
    
    # 记录结果
    results['accuracy_test'].append(test_accuracy)
    results['loss_test'].append(test_loss)
    results['accuracy_train'].append(train_accuracy)
    results['loss_train'].append(train_loss)
    results['communication_round'].append(round)
    
    # 输出日志
    print(f"Round {round}: Test Acc={test_accuracy:.4f}, Loss={test_loss:.4f}")
```

## 3. 可视化系统工作原理

`web_visualizer.py`实现了一个基于HTTP的可视化服务器：

1. **服务器启动**：监听指定端口（默认8000）
2. **结果加载**：从`results/`目录读取实验数据
3. **图表生成**：使用matplotlib生成培训过程图表
4. **Web界面**：提供HTML界面展示实验结果和图表

可视化服务器核心功能：
```python
def main():
    # 解析命令行参数
    parser = argparse.ArgumentParser()
    parser.add_argument('-p', '--port', default=8000, type=int, help='Port to run the server on')
    args = parser.parse_args()
    
    # 创建HTTP请求处理器
    handler = create_request_handler()
    
    # 启动HTTP服务器
    with socketserver.TCPServer(("", args.port), handler) as httpd:
        print(f"Serving at port {args.port}")
        print(f"Open http://localhost:{args.port} in your browser")
        httpd.serve_forever()
```

处理数据和生成图表：
```python
def generate_plots(dataset_name, experiment_id):
    # 加载实验数据
    data = np.load(f"results/{dataset_name}/{experiment_id}.npz", allow_pickle=True)
    results = data['results'].item()
    
    # 提取训练指标
    rounds = results['communication_round']
    accuracy_test = results['accuracy_test']
    loss_test = results['loss_test']
    
    # 生成图表
    plt.figure(figsize=(10, 6))
    plt.plot(rounds, accuracy_test, '-o')
    plt.xlabel('Communication Rounds')
    plt.ylabel('Test Accuracy')
    plt.title(f'{dataset_name} Test Accuracy')
    plt.grid(True)
    
    # 保存图表
    plot_path = f"results/{dataset_name}/plots/{experiment_id}_accuracy.png"
    plt.savefig(plot_path)
    
    return plot_path
```

## 4. 数据集处理细节

系统支持三种数据集，每种数据集的处理方式略有不同：

1. **MNIST/Fashion-MNIST**：
   - 28×28单通道灰度图像
   - 标准化处理：(pixel - 0.1307) / 0.3081
   - 使用较简单的CNN模型

2. **CIFAR-10**：
   - 32×32三通道彩色图像
   - 标准化处理：RGB通道各自标准化
   - 使用更复杂的CNN模型（更多层和特征图）

加载数据的代码示例：
```python
def get_data_loaders(dataset_name, batch_size, test_batch_size):
    if dataset_name == 'mnist':
        # MNIST数据集处理
        transform = transforms.Compose([
            transforms.ToTensor(),
            transforms.Normalize((0.1307,), (0.3081,))
        ])
        train_dataset = datasets.MNIST('./data', train=True, download=True, transform=transform)
        test_dataset = datasets.MNIST('./data', train=False, transform=transform)
        
    elif dataset_name == 'fashionmnist':
        # Fashion-MNIST数据集处理
        transform = transforms.Compose([
            transforms.ToTensor(),
            transforms.Normalize((0.2860,), (0.3530,))
        ])
        train_dataset = datasets.FashionMNIST('./data', train=True, download=True, transform=transform)
        test_dataset = datasets.FashionMNIST('./data', train=False, transform=transform)
        
    elif dataset_name == 'cifar10':
        # CIFAR-10数据集处理
        transform_train = transforms.Compose([
            transforms.RandomCrop(32, padding=4),
            transforms.RandomHorizontalFlip(),
            transforms.ToTensor(),
            transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))
        ])
        transform_test = transforms.Compose([
            transforms.ToTensor(),
            transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))
        ])
        train_dataset = datasets.CIFAR10('./data', train=True, download=True, transform=transform_train)
        test_dataset = datasets.CIFAR10('./data', train=False, transform=transform_test)
    
    # 创建数据加载器
    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)
    test_loader = DataLoader(test_dataset, batch_size=test_batch_size, shuffle=False)
    
    return train_loader, test_loader, train_dataset, test_dataset
```

## 5. 修复工具工作原理

`fix_plot.py`脚本解决了可视化显示问题，特别是中文字体不显示的问题：

1. **扫描结果目录**：查找所有数据集目录和实验结果
2. **备份原图**：保存原有图表的备份
3. **生成新图表**：使用英文标签创建新图表
4. **保存到指定位置**：将图表保存在正确的目录结构中

主要工作流程：
```python
def fix_all_plots():
    # 查找数据集
    datasets = ['mnist', 'fashionmnist', 'cifar10', 'quick_test']
    
    for dataset in datasets:
        # 查找图表目录
        plots_dirs = [
            os.path.join('results', dataset, 'plots'),
            os.path.join('results', 'plots', dataset)
        ]
        
        for plots_dir in plots_dirs:
            if os.path.exists(plots_dir):
                # 备份和删除旧图表
                backup_and_clear_old_plots(plots_dir, dataset)
                
                # 生成新图表
                create_example_plot(dataset, plots_dir)
```

## 6. 快速启动特性

`quick_start.py`提供简化配置的快速启动功能：

1. **加载简化配置**：使用`federated_learning_quick.json`
2. **减少参数规模**：更少的客户端数和通信轮数
3. **固定数据集**：默认使用MNIST（复杂度较低）
4. **结果存储**：将结果保存在`results/quick_test/`目录

```python
def quick_start():
    # 加载快速配置
    with open('federated_learning_quick.json', 'r') as f:
        config = json.load(f)
    
    # 设置随机种子保证结果可复现
    torch.manual_seed(42)
    
    # 初始化和运行系统
    run_federated_learning(config)
    
    print("Quick test completed. Results saved in results/quick_test/")
```

## 7. 总结

该联邦学习项目实现了以下核心功能：

1. **联邦学习算法**：基于FedAvg算法实现客户端本地训练和服务器聚合
2. **非IID数据分布**：支持数据异构性模拟，更接近真实场景
3. **多数据集支持**：MNIST、Fashion-MNIST和CIFAR-10
4. **可视化界面**：Web服务器展示训练过程和结果
5. **灵活配置**：丰富的参数设置，既支持完整实验，也支持快速测试

系统的主要工作流程是：配置加载 → 数据准备与分发 → 初始化模型 → 多轮联邦学习(客户端训练+服务器聚合) → 结果评估与记录 → 可视化展示。这种设计既实现了联邦学习的核心算法，又提供了灵活的研究平台支持不同的实验场景。
